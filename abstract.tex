\begin{abstract}

The performance of a software system depends on its configuration and workload. State-of-the-art performance modeling approaches either address configuration-dependent or workload-dependent performance behavior.  The relation and interaction of both factors and their influence on performance have not been systematically studied so far. Understanding to what extent configuration and workload---individually and combined---cause a software systemâ€™s performance to vary is key to understand whether performance models are generalizable, across different configurations and workloads. We would be able to determine whether a performance model is general and to what extent, whether we can efficiently transfer it to another setting, or whether need to entirely re-learn it with many configurations under a new workload. To shed light on this issue, we have conducted a \emph{systematic} empirical study of a multitude of configurations and workloads across a selection of
six configurable software systems. We have obtained a substantial number of black-box performance measurements and enriched them with statement coverage data to assess whether and how configuration choices and workloads interact and shape software performance. 

We found that a substantial amount of workload-specific differences cannot be learned using linear or monotonic transformation, which may limit the feasibility of existing transfer learning approaches. Our evaluation demonstrates that code utilization is a driving factor for workload-specific performance differences and that considering workload characteristics is a promising step towards more generalizable performance models for configurable software systems.
\end{abstract}
