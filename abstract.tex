\begin{abstract}
The performance characteristics of a software system depends to a significant extent on its configuration and workload. State-of-the-art performance modeling approaches either address configuration-dependent or workload-dependent performance behavior.  The relation and interaction of both factors and their influence on performance have not been systematically studied so far. Understanding to what extent configuration and workload---individually and combined---cause a software systemâ€™s performance to vary is key to understand whether performance models are generalizable, across different configurations and workloads. {\color{red}This way it would be possible to determine whether a performance model is general and to what extent, whether we can efficiently transfer it to another setting, or whether we need to entirely re-learn it with many configurations under a new workload.} To shed light on this issue, we have conducted a \emph{systematic} empirical study, analyzing a multitude of configurations and workloads across a six software systems We have obtained a substantial number of black-box performance measurements and enriched them with statement coverage data to assess whether and how configuration choices and workloads interact and shape software performance. 
Our evaluation demonstrates that code coverage (i.e., \textit{what} code is executed) and code utilization (i.e., \textit{how} covered code is executed) are driving factors for workload-specific performance differences and that coverage testing provides a practical, yet not sufficient means to detect unreliable workloads.
\end{abstract}
