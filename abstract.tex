\begin{abstract}

Non-functional properties such as software performance depend often on a variety of factors including software configuration choices and workloads.  
Such properties can be modeled using performance models learned from a sample set of observations. While varying workloads is common in practical performance testing, existing work on performance modeling, however, only \emph{systematically} studies the influence of \emph{either} configurations \emph{or} workloads on performance. 

For configuration-dependent performance modeling, the effect of varying the workload can be accounted for by transfer learning only if the workload-specific performance behavior is similar to some extent. 
Based on the similarity existing performance models can be reused or transformed, but have to be learned again from scratch if the performance behavior under a new workload is dissimilar.
So far, the underlying question of how consistent performance of a configurable software system is over different workloads, has not been studied. 
Thus, it remains unclear, if and to what extent configuration-dependent performance models are \emph{representative} of behavior under different workloads.

On this behalf, we address this issue and conduct a \emph{systematic} empirical study of a multitude of configurations and workloads across a selection of six configurable software systems. 
We enrich our black-box observations with statement coverage data to assess if and how configuration choices and workloads interact and shape software performance. 
{\color{blue}We found that â€¦ . Our results indicate...}

\end{abstract}
