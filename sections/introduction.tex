
%\paragraph*{\color{purple}Context}
Most modern software systems can be customized via configuration options to meet user demands. The selection of configuration options can enable desired functionality or tweak non-functional aspects of a software system, such as improving performance or energy consumption. The relationship of configuration choices and their influence on performance has been extensively studied in the literature. The backbone of performance estimation are prediction models that map a given configuration to the estimated performance value. Learning performance models relies on a training set of configuration-specific performance measurements~~\cite{dorn2020,siegmundPerformanceinfluenceModelsHighly2015,haDeepPerf2019,perfAL,guoVariabilityawarePerformancePrediction2013,sarkarCostEfficientSamplingPerformance,guo_2018_data,fourier_learning_2015,perLasso}. For established approaches, however, such observations usually employ only a single workload which aims at emulating a specific real-world application scenario.

The choice of the workload (i.e., input fed to the software system) is known to influence the performance of configurable software systems in different ways. Besides apparent interactions, such as performance scaling with the size of a workload, qualitative aspects can result in more complex and non-trivial performance interactions. For instance, \citeauthor{alves_sampling_2020} have shown that the video transcoder \textsf{x264} exhibits different performance distributions depending on the video source file~\cite{alves_sampling_2020} and \citeauthor{liao_2020_using_emse} have demonstrated this for stream processing applications~\cite{liao_2020_using_emse}. As varying the workload adds another layer of complexity to modeling performance, we cannot guarantee that performance models trained with a single workload \textit{generalize} to arbitrary workloads and make meaningful estimations. 

%\paragraph*{\color{purple}Motivation}
To overcome this limitation, in literature, two different directions have been pursued. First, performance models trained using a specific workload can be adapted to another specific workload. Second,  one can specify workload characteristics as further independent variables when modeling configuration-dependent performance~\cite{koc_satune_2021}.\todo{further references}
The first strategy direction uses transfer learning techniques, where, given an existing performance model, in a separate step only the difference to a new environment is learned. Such a transfer function encodes which configuration optionsâ€™ influence on performance is sensitive to workload variation, more specifically the differences between the original and new workload. While transfer learning is an effective strategy that is not limited to varying workloads~\cite{jamshidi_learning_2018}, but can also be applied to different versions~\cite{jamishidi_transfer_2017,jamshidi_transfer_gp_2017,martin_transfer_2021}, or hardware setups~\cite{ding_bayesian_2020}, its main limitation is that the transfer function is specific to a difference of two environments.

In contrast to transfer learning, a more generalist approach is to consider the input fed to a software system as a further dimension for modeling performance. Here, a workload can be characterized by properties that---individually or in conjunction with software configuration options---influence performance. For such a strategy to work, we require knowledge of the characteristics of a workload that influence performance. This strategy has been effectively tested for a  variety of application-domains, such as program verification~\cite{koc_satune_2021} and {\color{red}blank}\todo{further references}. However, the added complexity comes at significant cost. Besides the additional step of domain-specific workload characterization, screening the inflated configuration-workload problem space for relevant features incurs more measurements required to learn accurate performance models.  

%\paragraph*{\color{purple}Problem}
The existing body of work reflects the prevalence and importance of the workload influence on software systems~\cite{}\todo{references}. While the approaches outlined above weed out configuration options that are insensitive to workload variation, little is known about the quality and driving factors of the interplay between configuration options and workloads. Our understanding of this cross-factor relationship lacks knowledge of the following aspects:

\begin{compactitem}
	\item How difficult or complex is the transformation of a performance model to another workload? 
	\item What drives complexity in such transformations? 
	\item Are few or many configuration options sensitive to varying the workload?
	\item What are the driving factors of the interplay between configuration options? 
	\item Do some workloads cover feature code less exhautively than others, do workloads use feature code in different ways?
\end{compactitem}

In absence of a systematic study that sheds light on whether and how configuration options and workload choices interact with regard to performance, we address this isssue in this paper. 
We have conducted an empirical study of {\color{red}xx\,xxx} configurations and {\color{red}xx} workloads across six configurable software systems to provide a broad picture of the interaction of configuration and workload when learning performance models and estimating a configuration's performance (i.e., response time). Aside from studying the sole effects of workload variation on performance behavior and performance model influences, we explore possible driving factors. To this end, we enrich performance observations with corresponding statement coverage data to understand workload variation at finer granularity.

Our findings suggest that {\color{red} \ldots. Our categorization can help practitioners and researchers to obtain representative performance models more efficiently as we provide a set of scenarios to test for.}

To summarize, we make the following contributions: 

\begin{compactitem}
	\item An empirical study of {\color{red}xx\,xxx} configurations and {\color{red}xx} workloads across six configurable software systems of whether and how the interaction of workloads with configuration options influences performance;
	
	\item A catalogue of {\color{red}X} interaction scenarios alongside possible explanations on how to possibly detect them and incorporate them into modeling configuration-dependent performance	;
	
	\item A companion Web site\footnote{\url{https://add.url.here}} with supplementary material including performance and coverage measurements, experiment workloads and configurations, as well as additional visualizations left out due to space limitations.
\end{compactitem}


